[
  {
    "objectID": "seminar_pages/ShuF23.html",
    "href": "seminar_pages/ShuF23.html",
    "title": "Dynamics of bimatrix games and a social-climate model",
    "section": "",
    "text": "Speaker: Longmei Shu (Dartmouth, Mathematics)\nDate: 10/3/23\nAbstract: In the first part of this presentation we consider replicator dynamics with feedback-evolving games, where the payoffs switch between two different matrices. Although each payoff matrix on its own represents an environment where cooperators and defectors can’t coexist stably, we show that it’s possible to design appropriate switching control laws and achieve persistent oscillations of strategy abundance. In the second part we couple the forest dieback model with human behaviors. Using evolutionary game theory, we build a time-delay system where forest growth is impacted by both temperature and human mitigation choices, the latter being informed by temperature forecasts. Simulations of the coupled system over 200 years show us varying outcomes."
  },
  {
    "objectID": "seminar_pages/TBA1F24.html",
    "href": "seminar_pages/TBA1F24.html",
    "title": "TBA",
    "section": "",
    "text": "Speaker: TBA (TBA)\nDate: 10/22/24\nAbstract: TBA"
  },
  {
    "objectID": "seminar_pages/AllenS23.html",
    "href": "seminar_pages/AllenS23.html",
    "title": "Natural selection for collective action",
    "section": "",
    "text": "Speaker: Ben Allen (Emmanuel College)\nDate: 5/23/23\nAbstract: Collective action – behavior that arises from the combined actions of multiple individuals – is observed across living beings. The question of how and why collective action evolves has profound implications for behavioral ecology, multicellularity, and human society. Collective action is challenging to model mathematically, due to nonlinear fitness effects and the consequences of spatial, group, and/or family relationships. We derive a simple condition for collective action to be favored by natural selection. A collective’s effect on the fitness of each individual is weighted by the relatedness between them, using a new measure of collective relatedness. If selection is weak, this condition can be evaluated using coalescent theory. More generally, our result applies to any synergistic social behavior, in spatial, group, and/or family-structured populations. We use this result to obtain conditions for the evolution of collective help among diploid siblings, subcommunities of a network, and hyperedges of a hypergraph. We also obtain a condition for which of two strategies is favored in a game between siblings, cousins, or other relatives. Our work provides a rigorous basis for extending the notion of “actor”, in the study of social behavior, from individuals to collectives."
  },
  {
    "objectID": "seminar_pages/TBA3F24.html",
    "href": "seminar_pages/TBA3F24.html",
    "title": "TBA",
    "section": "",
    "text": "Speaker: TBA (TBA)\nDate: 11/12/24\nAbstract: TBA"
  },
  {
    "objectID": "seminar_pages/AmbartsoumianF22.html",
    "href": "seminar_pages/AmbartsoumianF22.html",
    "title": "Broken Rays, Cones, and Stars in Tomography",
    "section": "",
    "text": "Speaker: Gaik Ambartsoumian (UT Arlington)\nDate: 10/4/23\nAbstract: Mathematical models of various imaging modalities are based on integral transforms mapping a function (representing the image) to its integrals along specific families of curves or surfaces. Those integrals are generated by external measurements of physical signals, which are sent into the imaging object, get modified as they pass through its medium and are captured by sensors after exiting the object. The mathematical task of image reconstruction is then equivalent to recovering the image function from the appropriate family of its integrals, i.e. inverting the corresponding integral transform (often called a generalized Radon transform). A classic example is computerized tomography (CT), where the measurements of reduced intensity of X-rays that have passed though the body correspond to the X-ray transform of the attenuation coefficient of the medium. Image reconstruction in CT is achieved through inversion of the X-ray transform. In this talk, we will discuss several novel imaging techniques using scattered particles, which lead to the study of generalized Radon transforms integrating along trajectories and surfaces containing a ``vertex’’. The relevant applications include single-scattering X-ray tomography, single-scattering optical tomography, and Compton camera imaging. We will present recent results about injectivity, inversion, stability and other properties of the broken ray transform, conical Radon transform and the star transform."
  },
  {
    "objectID": "seminar_pages/GrantF24.html",
    "href": "seminar_pages/GrantF24.html",
    "title": "TBA",
    "section": "",
    "text": "Speaker: Curtis Grant (Northwestern)\nDate: 10/8/24\nAbstract: TBA"
  },
  {
    "objectID": "seminar_pages/ZhuW24.html",
    "href": "seminar_pages/ZhuW24.html",
    "title": "Symmetry-Preserving Machine Learning: Theory and Applications",
    "section": "",
    "text": "Speaker: Wei Zhu (UMass Amherst)\nDate: 1/16/24\nAbstract: Symmetry is prevalent in a variety of machine learning and scientific computing tasks, including computer vision and computational modeling of physical and engineering systems. Empirical studies have demonstrated that machine learning models designed to integrate the intrinsic symmetry of their tasks often exhibit substantially improved performance. Despite extensive theoretical and engineering advancements in symmetry-preserving machine learning, several critical questions remain unaddressed, presenting unique challenges and opportunities for applied mathematicians. Firstly, real-world symmetries rarely manifest perfectly and are typically subject to various deformations. Therefore, a pivotal question arises: Can we effectively quantify and enhance the robustness of models to maintain an “approximate” symmetry, even under imperfect symmetry transformations? Secondly, although empirical evidence suggests that symmetry-preserving models require fewer training data to achieve equivalent accuracy, there is a need for more precise and rigorous quantification of this reduction in sample complexity attributable to symmetry preservation. Lastly, considering the non-convex nature of optimization in modern machine learning, can we ascertain whether algorithms like gradient descent can guide symmetry-preserving models to indeed converge to objectively better solutions compared to their generic counterparts, and if so, to what degree? In this talk, I will provide an overview of my research addressing these intriguing questions. Surprisingly, the answers are not as straightforward as one might assume and, in some cases, are counterintuitive. My approach employs an interesting blend of applied probability, harmonic analysis, differential geometry, and optimization. However, specialized knowledge in these areas is not required."
  },
  {
    "objectID": "seminar_pages/JonesS23.html",
    "href": "seminar_pages/JonesS23.html",
    "title": "Nash Equilibrium in a Low-Information Vote Trading Game",
    "section": "",
    "text": "Speaker: Matt Jones (Yale)\nDate: 3/28/23\nAbstract: Groups are often asked to make decisions about a wide range of issues. If each issue is decided by a separate vote, voters are incentivized to give away their votes on issues they deem unimportant in exchange for additional votes on the most critical issues. This scenario leads to a vote trading game in which voters must decide which trades to offer to maximize their final utility. We begin with a discrete model of voter utility and then move to the more general continuous model. In both cases, we analyze the game by studying their Nash equilibria and evaluating how the underlying utility distribution affects player behavior."
  },
  {
    "objectID": "seminar_pages/BarnettF22.html",
    "href": "seminar_pages/BarnettF22.html",
    "title": "Equispaced Fourier representations for efficient Gaussian process regression from a billion data points",
    "section": "",
    "text": "Speaker: Alex Barnett (Flatiron Institute)\nDate: 10/25/23\nAbstract: Gaussian process regression is widely used in geostatistics, time-series analysis, and machine learning. It infers an unknown continuous function in a principled fashion from noisy measurements at scattered data points. The prior on the function is Gaussian, with covariance given by some user-chosen translationally invariant kernel. Yet has been limited to about, even with modern low-rank methods. Focusing on low spatial dimension (1–3), we present a GP regression method using kernel approximation by an equispaced quadrature grid in the Fourier domain. This enables the iterative solution of a smaller Toeplitz linear system, exploiting both the FFT and the nonuniform FFT to give cost. The result is often one to two orders of magnitude faster than state of the art methods, and enables cheap massive-scale regressions. For example, for a 2D Matern-3/2 kernel and points, the posterior mean function is found to 3-digit accuracy in two minutes on a desktop. This is a joint work with Philip Greengard (Columbia) and Manas Rachh (Flatiron Institute)."
  },
  {
    "objectID": "seminar_pages/FrostW23.html",
    "href": "seminar_pages/FrostW23.html",
    "title": "Eigenvectors from eigenvalues sparse principal component analysis",
    "section": "",
    "text": "Speaker: Rob Frost (Dartmouth, Geisel)\nDate: 2/14/23\nAbstract: We present a novel technique for sparse principal component analysis. This method, named eigenvectors from eigenvalues sparse principal component analysis (EESPCA), is based on the formula for computing squared eigenvector loadings of a Hermitian matrix from the eigenvalues of the full matrix and associated sub-matrices. We explore two versions of the EESPCA method: a version that uses a fixed threshold for inducing sparsity and a version that selects the threshold via cross-validation. Relative to the state-of-the-art sparse PCA methods of Witten et al., Yuan and Zhang, and Tan et al., the fixed threshold EESPCA technique offers an order-of-magnitude improvement in computational speed, does not require estimation of tuning parameters via cross-validation, and can more accurately identify true zero principal component loadings across a range of data matrix sizes and covariance structures. Importantly, the EESPCA method achieves these benefits while maintaining out-of-sample reconstruction error and PC estimation error close to the lowest error generated by all evaluated approaches. EESPCA is a practical and effective technique for sparse PCA with particular relevance to computationally demanding statistical problems such as the analysis of high-dimensional datasets or application of statistical techniques like resampling that involve the repeated calculation of sparse PCs. Paper link: https://doi.org/10.1080/10618600.2021.1987254."
  },
  {
    "objectID": "seminar_pages/ZhangF22.html",
    "href": "seminar_pages/ZhangF22.html",
    "title": "Coupling physics-deep learning inversion",
    "section": "",
    "text": "Speaker: Lu Zhang (Columbia University)\nDate: 10/18/23\nAbstract: In recent years, there is great interest in using deep learning to geophysical/medical data inversion. However, direct application of end-to-end data-driven approaches to inversion have quickly shown limitations in the practical implementation. Due to the lack of prior knowledge on the objects of interest, the trained deep learning neural networks very often have limited generalization. In this talk, we introduce a new methodology of coupling model-based inverse algorithms with deep learning for two typical types of inversion problems. In the first part, we present an offline-online computational strategy for coupling classical least-squares based computational inversion with modern deep learning based approaches for full waveform inversion (FWI) to achieve advantages that can not be achieved with only one of the components. An offline learning strategy is used to construct a robust approximation to the inverse operator and utilize it to design a new objective function for the online inversion with new datasets. In the second part, we present an integrated machine learning and model-based iterative reconstruction framework for joint inversion problems where additional data on the unknown coefficients are supplemented for better reconstructions. The proposed method couples the supplementary data with the partial differential equation (PDE) model to make the data-driven modeling process consistent with the model-based reconstruction procedure. The impact of learning uncertainty on the joint inversion results are also investigated."
  },
  {
    "objectID": "seminar_pages/RenS24.html",
    "href": "seminar_pages/RenS24.html",
    "title": "Inverse problems to mean field game systems: analysis and computation",
    "section": "",
    "text": "Speaker: Kui Ren (Columbia)\nDate: 5/21/24\nAbstract: Mean field game models have been developed in different application areas. We will provide an overview of recent developments in inverse problems to mean field game models where we are interested in reconstructing missing information from observed data. We present a few different scenarios where differential data allows for the unique identification of model parameters in various forms, as well as numerical methods for computing the inverse solutions."
  },
  {
    "objectID": "seminar_pages/TBA2F24.html",
    "href": "seminar_pages/TBA2F24.html",
    "title": "TBA",
    "section": "",
    "text": "Speaker: TBA (TBA)\nDate: 10/29/24\nAbstract: TBA"
  },
  {
    "objectID": "seminar_pages/PalmerW23.html",
    "href": "seminar_pages/PalmerW23.html",
    "title": "Applied Geometric Measure Theory from DeepCurrents to Topological Defects",
    "section": "",
    "text": "Speaker: David Palmer (MIT)\nDate: 2/7/23\nAbstract: Choosing the right representation of geometry can often simplify knotty computational problems and expose new opportunities. I will talk about some of our work devising computational representations of geometry inspired by geometric measure theory and, in particular, minimal currents. First, while neural implicit representations offer a flexible way to encode surfaces and learn families of surfaces in computer vision, most methods are unable to reconstruct surfaces with boundary curves. In DeepCurrents (joint work with Dima Smirnov, Stephanie Wang, Albert Chern, and Justin Solomon), we propose a new hybrid representation that parametrizes currents via neural implicit functions and solves a minimal surface problem. By modifying the ambient metric such that the target geometry is minimal, we can learn arbitrary surfaces and families of surfaces with boundary, providing a building block for larger-scale surface representations. A completely different application of currents is to the problem of computing line or nematic fields, cross fields, and their generalizations on surfaces. Such fields are important to applications in computer graphics and computational engineering, and they have recently shown up in models of biological morphogenesis. Singularities or topological defects are an essential feature of such fields. But singularities challenge classical field optimization methods, whose energies tend to diverge or depend on discretization in their presence. By reformulating field optimization in terms of minimal currents in circle bundles, we obtain a convex relaxation that treats singularities as first-class citizens and yields reliable optimization."
  },
  {
    "objectID": "seminar_pages/SayamaF23.html",
    "href": "seminar_pages/SayamaF23.html",
    "title": "Studying Social Fragmentation Using Adaptive Network-based Artificial Society Models",
    "section": "",
    "text": "Speaker: Hiroki Sayama (Binghamton)\nDate: 11/7/23\nAbstract: The rapid adoption of social media and smartphones that has occurred over the past few decades has made it dramatically easier for everyone to freely choose and access a variety of information sources. However, numerous studies have shown that such a society with faster and more personalized information circulation is not necessarily conducive to integration and consensus building, but on the contrary, tends to promote division among communities with incompatible views. It is thus crucial to understand the possible dynamical mechanisms that cause social fragmentation and to properly manage them according to societal conditions and needs. “Artificial society” research plays an important role in this front, developing mathematical models of social dynamics and exploring possible forms and behaviors of various hypothetical societies, rather than studying the current state of society only empirically. In this talk, I will introduce two examples of our recent studies on social fragmentation using coevolutionary adaptive social network models as concrete examples of artificial society research. The first study investigated the effects of individual behavioral traits on macroscopic social evolution using a simple opinion dynamics model on adaptive social networks. The second study used a more detailed computational agent-based model to demonstrate that a “third state” society, in which both topological connectivity and opinion diversity are simultaneously maintained, is possible when agents are behaviorally heterogeneous. This key finding obtained in the second study was also confirmed using an extended version of the first model as well, demonstrating the robustness of the finding about the importance of behavioral diversity within society."
  },
  {
    "objectID": "seminar_pages/BovierS24.html",
    "href": "seminar_pages/BovierS24.html",
    "title": "A branching random walk with self repulsion",
    "section": "",
    "text": "Speaker: Anton Bovier (UBonn, Germany)\nDate: 5/28/24\nAbstract: We consider a discrete time branching random walk where each particle splits into two at integer times and the offspring move independently by a normal random variable. We introduce a penalty that penalises particles that get within a distance epsilon of each other. We analyse the most likely configurations of particles under the tilted measure for a fixed time horizon N. It turns out that spread very quickly to a distance 2^{2N/3} and show a very abrupt change in behaviour at time 2N/3. This is joint work with Lisa Hartung, Frank den Hollander and Stefan Müller."
  },
  {
    "objectID": "seminar_pages/BrooksF23.html",
    "href": "seminar_pages/BrooksF23.html",
    "title": "Emergence of polarization in a sigmoidal bounded-confidence model of opinion dynamics",
    "section": "",
    "text": "Speaker: Heather Zinn Brooks (Harvey Mudd)\nDate: 10/17/23\nAbstract: We propose a nonlinear bounded-confidence model (BCM) of continuous time opinion dynamics on networks with both persuadable individuals and zealots. The model is parameterized by a scalar γ, which controls the steepness of a smooth influence function that encodes the relative weights that nodes place on the opinions of other nodes. When γ = 0, this influence function exactly recovers Taylor’s averaging model; when γ → ∞, the influence function converges to that of a modified Hegselmann–Krause (HK) BCM. Unlike the classical HK model, however, our sigmoidal bounded-confidence model (SBCM) is smooth for any finite γ. We show that the set of steady states of our SBCM is qualitatively similar to that of the Taylor model when γ is small and that the set of steady states approaches a subset of the set of steady states of a modified HK model as γ → ∞. For several special graph topologies, we give analytical descriptions of important features of the space of steady states. A notable result is a closed-form relationship between the stability of a polarized state and the graph topology in a simple model of echo chambers in social networks. Because the influence function of our BCM is smooth, we are able to study it with linear stability analysis, which is difficult to employ with the usual discontinuous influence functions in BCMs. This is joint work with Phil Chodrow and Mason Porter."
  },
  {
    "objectID": "seminar_pages/JebelliW24.html",
    "href": "seminar_pages/JebelliW24.html",
    "title": "Kernel Smoothing Operators on Thick Open Domains",
    "section": "",
    "text": "Speaker: Mohammad Javad Latifi Jebelli (Dartmouth, Mathematics)\nDate: 1/9/24\nAbstract: Given an appropriate kernel function, it is known that the convolution operator would converge to the identity operator as the scaling parameter goes to zero. In this talk, we discuss the approximation properties of the ‘normalized’ convolution operators on certain domains in Euclidean space. Despite the fact that normalization breaks the symmetry of the convolution operators, we show that a local Hardy-Littlewood inequality holds in L^p(X), where p&gt;1 and X is a ‘thick’ domain in n-dimensional Euclidean space. Using this inequality, we establish pointwise and Lp(X) convergence for the family of convolution operators. We demonstrate the application of such smoothing operators to sea ice piecewise-continuous density, velocity, and stress fields from discrete element models of sea ice dynamics."
  },
  {
    "objectID": "seminar_pages/DemidenkoF23.html",
    "href": "seminar_pages/DemidenkoF23.html",
    "title": "M-statistics: Optimal Statistical Inference for a Small Sample",
    "section": "",
    "text": "Speaker: Eugene Demidenko (Dartmouth, Mathematics)\nDate: 9/12/23\nAbstract: This talk presents a recently published book with the same title. We start with the 250-year-old problem of estimation binomial probability. The classic estimator, as the proportion of successes, m/n, contradicts common sense when the event does not happen or happens all the time. We revive Laplace’s law of succession estimator, (m+1)/(n+2), using a new statistical theory, M-statistics. Neither mean nor variance plays a role in the new theory. The current practice of statistical inference relies on asymptotic methods (large n), such as maximum likelihood (ML). The small-sample exact statistical inference is available only for a few examples, primarily linear models. Our theory requires a statistic with a known cumulative distribution function dependent on an unknown parameter. Two parallel competing tracks of inferences are offered under the umbrella of M-statistics: maximum concentration (MC) and mode (MO) statistics, which is why M=MC+MO. Having an optimal exact dual double-sided confidence interval (CI) and test, the point estimator is derived as the limit point of the CI when the confidence level approaches zero. When a statistic is sufficient, the MO-estimator, as the limit of the unbiased CI, coincides with the ML estimator. Our theory extends to multi-parameter statistical inference. Multiple examples illustrate the talk. This talk is accessible to undergraduate students who took elementary probability/statistics course."
  },
  {
    "objectID": "seminar_pages/LucibelloS24.html",
    "href": "seminar_pages/LucibelloS24.html",
    "title": "The Exponential Capacity of Dense Associative Memories",
    "section": "",
    "text": "Speaker: Carlo Lucibello (Bocconi University, Italy)\nDate: 4/16/24\nAbstract: Recent generalizations of the Hopfield model of associative memories are able to store a number P of random patterns that grows exponentially with the number N of neurons, P=exp(αN). Besides the huge storage capacity, another interesting feature of these networks is their connection to the attention mechanism which is part of the Transformer architectures and to the score function of Denoising Diffusion Models. In this work, we consider a generic family of pattern ensembles, and thanks to the statistical mechanics analysis of an auxiliary Random Energy Model, we are able to provide exact asymptotic thresholds for the retrieval of a typical pattern, α1, and lower bounds for the maximum of the load α for which all patterns can be retrieved, αc. Additionally, we characterize the size of the basins of attractions. We discuss in detail the cases of Gaussian and spherical patterns, and show that they display rich and qualitatively different phase diagrams."
  },
  {
    "objectID": "seminar_pages/VosoughiS23.html",
    "href": "seminar_pages/VosoughiS23.html",
    "title": "Unsupervised Structural Graph Representation Learning",
    "section": "",
    "text": "Speaker: Soroush Vosoughi (Dartmouth, CS)\nDate: 4/25/23\nAbstract: In this presentation, I will discuss our lab’s research on unsupervised structural graph representation learning. It is essential to differentiate between representations that capture structural roles and those that capture local information in graphs (microscopic representations, such as node2vec). Structural embeddings can capture the global roles of nodes, edges, and subgraphs in a graph. This means that nodes that perform similar functions in a graph will have similar vector representations, regardless of their distance from each other in the graph. Our framework’s core feature is its capability for unsupervised learning of versatile and universal representations that capture the structural roles of nodes, edges, and subgraphs (communities) in a dynamic attributed graph. These general-purpose representations eliminate the need for time-consuming and biased feature engineering and are suitable for both unsupervised and supervised tasks, including clustering and classification. Finally, I will discuss the potential of these general-purpose representations for supervised and unsupervised learning in downstream tasks on various types of graphs, such as social and financial networks."
  },
  {
    "objectID": "seminar_pages/ZhouS24.html",
    "href": "seminar_pages/ZhouS24.html",
    "title": "Acceleration for MCMC methods on discrete states",
    "section": "",
    "text": "Speaker: Bohan Zhou (UC Santa Barbara)\nDate: 5/6/24\nAbstract: As ChatGPT and Midjourney rise to prominence on a global scale, generative models have captivated the public’s attention. This talk explores the concept of flow-based generative models aimed at achieving a target distribution. We focus on designing a Markov-chain (for discrete time) or a flow (for continuous time) to converge from a simple initial distribution to the desired target. Specifically, we propose a Nesterov type method to enhance the efficiency of the classical Markov Chain Monte Carlo (MCMC) algorithm (for example, Metropolis-Hastings algorithms) on finite graphs. We interpret MCMC on a finite graph as the gradient flow of a divergence functional and incorporate the concept of “momentum” inspired by the Nesterov acceleration method. This addition allows us to propose a second-order ODE in the probability space, which can be viewed as the accelerated version of MCMC process. At last, we provide analysis to justify the convergence of the algorithm and numerical examples to validate the effectiveness of our approach."
  },
  {
    "objectID": "seminar_pages/MooreF24.html",
    "href": "seminar_pages/MooreF24.html",
    "title": "TBA",
    "section": "",
    "text": "Speaker: Cris Moore (Binghampton)\nDate: 10/15/24\nAbstract: TBA"
  },
  {
    "objectID": "seminar_pages/MehtaF22.html",
    "href": "seminar_pages/MehtaF22.html",
    "title": "Complex systems in high dimensions: from Machine Learning to Microbial Ecology",
    "section": "",
    "text": "Speaker: Pankaj Mehta (Boston University)\nDate: 10/11/23\nAbstract: In this talk, I will give an overview of recent work from the group that draws on techniques from statistical physics of disordered systems (Random Matrix Theory, Cavity Method) to understand complex systems in high dimensions. In the first part of this talk, I will discuss how we can understand the ability of over-parameterized statistical models to make accurate predictions even when the number of fitting parameters is much larger than the number of training data points (the so called double-descent phenomenon). If time permits, in the second part of the talk I will discuss how similar techniques also yield interesting insights into complex microbial ecosystems. References: Physical Review Research 4, 013201 (2022); arXiv:2103.14108; Science 361, 469-474 (2018); Physical Review Letters 125 048101 (2020); Physical Review E 104, 034416 (2020)."
  },
  {
    "objectID": "seminar_pages/ValesW24.html",
    "href": "seminar_pages/ValesW24.html",
    "title": "Energy conservative quadrature based hyperreduction of Lagrangian hydrodynamics problems",
    "section": "",
    "text": "Speaker: Chris Vales (UNH)\nDate: 3/5/24\nAbstract: Dimension reduction methods are used to approximate the numerical discretization of a model in order to reduce the computational cost of its simulation while staying faithful to the full dynamics. To achieve this, projection-based methods construct a reduced basis from full simulation data and project the dynamics onto the spanned linear subspace. For nonlinear problems, hyper-reduction methods are additionally needed to remove the dependence of the nonlinear terms on the full problem’s size, completing the reduction process. In this work, we develop an energy conservative hyperreduction method for hydrodynamics PDE problems discretized on a Lagrangian moving grid by high order finite element methods. Based on an existing empirical quadrature procedure, our method employs sparse numerical quadrature rules to estimate the model’s nonlinear integral terms with a chosen degree of accuracy while ensuring that energy is conserved. We apply our method to well established benchmark problems, demonstrating that it achieves superior energy conservation and similar accuracy and computational speedup compared to the preexisting, non-conservative method."
  },
  {
    "objectID": "seminar_pages/TungF24.html",
    "href": "seminar_pages/TungF24.html",
    "title": "TBA",
    "section": "",
    "text": "Speaker: Hwai-Ray Tung (University of Utah)\nDate: 11/19/24\nAbstract: TBA"
  },
  {
    "objectID": "seminar_pages/LorenzoSS24.html",
    "href": "seminar_pages/LorenzoSS24.html",
    "title": "Koopman operator theory for enhanced Pacific SST forecasting",
    "section": "",
    "text": "Speaker: Paula Lorenzo Sánchez (University of Bologna)\nDate: 6/28/24\nAbstract: El Niño-Southern Oscillation (ENSO) is a complex climatic phenomenon with significant impacts on global weather patterns and ecosystems. Improving ENSO predictability is therefore an issue of high societal value. However, Global Circulation Models present severe biases when predicting ENSO, and their skill remains comparable to that of vastly simpler empirical models such as Linear Inverse Models (LIMs). LIMs, however, rely on linear dynamics, and they have inherent limitations in capturing the behavior of non-linear phenomena. In this context, Koopman operator theory has emerged as a powerful mathematical framework, offering a novel perspective for analyzing complex non-linear systems, such as ENSO. In this study, we investigate the potential of Koopman operator theory to enhance ENSO forecasting accuracy. Leveraging 2000 years of tropical SST pre-industrial CESM data, we have assessed the skill of the Niño 3.4 index forecasts using the Koopman framework and compared it to the benchmark set by LIMs. Our analysis includes sensitivity testing of both methods across various parameters, such as retained variability and data length used for operator computations. Our findings reveal nuances in the robustness of Koopman Operator estimates, particularly evident when using shorter training periods, contrasting with more stable LIM counterparts. However, a notable breakthrough emerges as we demonstrate the higher skill of Koopman Ensemble Forecasts (KEFs), showcasing consistent improvements over linear models. Additionally, the Koopman approach seems to capture the variability of the western Pacific, as well as the occurrence of El Niño and La Niña events, providing fundamental potential for event forecasting. The comparative analysis highlights the potential of Koopman operator theory in advancing ENSO forecasting beyond linear models. The utilization of KEFs emerges as a promising strategy, demonstrating enhanced forecasting capabilities. Yet, challenges in robustness persist, particularly in shorter data spans, signaling avenues for further refinement. Overall, these findings underscore the significance of the Koopman framework and lay the groundwork for future research aimed at refining methodologies for more accurate predictions in complex climatic systems."
  },
  {
    "objectID": "seminar_pages/WatkinsF23.html",
    "href": "seminar_pages/WatkinsF23.html",
    "title": "Dynamics of coupled Arctic air-ice-ocean interactions from floe scale to basin scale",
    "section": "",
    "text": "Speaker: Daniel Watkins (Brown)\nDate: 10/10/23\nAbstract: Sea ice is a defining component of the coupled Arctic air-ice-ocean system. Sea ice mediates the exchange of momentum, heat, and moisture between the atmosphere and the ocean and is therefore a critical component for Earth system modeling, including climate prediction and weather forecasting. Ice motion results from the complex interaction of stresses from the winds and ocean currents, gravity, and Earth’s rotation. The motion and deformation of the ice resulting from these interacting stresses depends on the spatially and temporally varying ice strength, and on the orientation of the stresses relative to coastal features and the ice-ocean boundary. The compounded effects of small forces across large areas results in shearing, cracking, and opening of the ice surface. Many sea ice properties exhibit power law relationships across spatial and temporal scales. In this talk, I’ll present recent results on air-ice-ocean dynamics based on two complementary types of observations: in situ measurements from buoys and autonomous weather stations deployed during the Multidisciplinary drifting Observatory for the Study of Arctic Climate (MOSAiC), and remote sensing observations from satellite imagery via the Ice Floe Tracker (IFT) algorithm. Our results highlight the multiscale nature of sea ice motion. The MOSAiC buoys were deployed in a nested array allowing measurement of differential ice motion at hourly timescales. From these measurements, we show that abrupt changes in ice dynamics are associated with transitions in ocean seafloor topography. Topographic effects are particularly strong in tidal and inertial frequency bands, producing effects on ice deformation at daily and twice daily timescales at spatial scales of a few kilometers. Additionally, current jets at shelf boundaries align with high ice drift speeds, likely contributing to enhanced shear in the ice. Analysis of the IFT floe trajectories over the last 20 years shows sharp gradients in the fraction of the drift attributable to wind forcing over the Greenland continental shelf, suggesting that accurate representation of ocean currents is critical for modeling and forecasting ice drift in the region. Finally, I will present new measurements of power law behavior in ice dynamics, including the importance of accounting for seasonality in describing ice properties."
  },
  {
    "objectID": "seminar_pages/ZhaoS24.html",
    "href": "seminar_pages/ZhaoS24.html",
    "title": "Optimal transport with covariates: Wasserstein barycenter and its extensions",
    "section": "",
    "text": "Speaker: Wenjun Zhao (Brown)\nDate: 3/26/24\nAbstract: Optimal transport has emerged as a powerful tool in various fields, such as image processing, statistics, and data analysis. In this talk, we introduce the Wasserstein barycenter problem and its extension to continuous factors. To showcase its applicability in statistics, we propose a general framework using the barycenter problem for conditional density estimation and simulation. Real-data examples within purely data-driven settings will be presented to demonstrate our methodologies. If time allows, we will discuss its two extensions: (1) conditional barycenter, to preserve partial information of covariates if desired; (2) hierarchical barycenter, to incorporate covariates with hierarchical structures. This talk is based on joint work with Esteban G. Tabak (NYU Courant) and Giulio Trigila (CUNY Baruch)."
  },
  {
    "objectID": "seminar_pages/DowdleW24.html",
    "href": "seminar_pages/DowdleW24.html",
    "title": "Quantum Computing and the Battle for Quantum Advantage",
    "section": "",
    "text": "Speaker: Casey Dowdle (Dartmouth, Mathematics)\nDate: 2/20/24\nAbstract: Quantum computing has gained attention lately for several reasons, including academic, national security, and economic interests. Quantum advantage was first claimed in 2019 by Google in their random circuit sampling experiment. Since then there have been many other claims of quantum computers performing calculations faster than classical computers. However, every claim so far has been disproven through methods such as spoofing and tensor network simulation. In this talk I will give a brief overview of quantum theory, quantum computing, and the on-going controversy over quantum advantage."
  },
  {
    "objectID": "seminar_pages/MaunuS23.html",
    "href": "seminar_pages/MaunuS23.html",
    "title": "New Approaches to Positive Semidefinite Matrix Recovery",
    "section": "",
    "text": "Speaker: Tyler Maunu (Brandeis)\nDate: 4/11/23\nAbstract: We study algorithms that exploit constraint geometry to solve the matrix recovery problem over positive semidefinite matrices. We consider the problem in two separate settings. In the first setting, we study low-rank matrix recovery. We develop a new connection between this problem and the Wasserstein barycenter problem. Through this connection, we derive geometric first-order methods that have convergence guarantees in Bures-Wasserstein distance. In the second setting, we study the problem of graph Laplacian matrix recovery. In this setting, we derive first-order methods that exploit the constraint set geometry that again are guaranteed to efficiently recover the underlying matrix. Experiments on simulated and real data demonstrate the advantages of our new methodologies over existing methods."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Current Seminar",
    "section": "",
    "text": "The Applied & Computational Mathematics seminar (ACMS) at Dartmouth brings together researchers with common interests in developing mathematical and computational tools to study real-world complex phenomena. The seminar includes talks broadly on various areas of mathematics such as complex systems, computational science, data science, dynamical systems, evolutionary dynamics, game theory, machine learning, mathematical biology, network science, numerical analysis, optimization, probability theory & stochastic processes, quantum computing, statistics, statistical mechanics, uncertainty quantification, etc.; hence these talks will keep the breadth of the audience in mind.\nThe seminar is held weekly on Tuesdays from 2:30 – 3:30 PM in Kemeny Hall, Room 007.\n\n\n* There will be two talks on Tuesday 10/8/24. The first will be Curtis Grant from 1-2 PM, and the second will be Weiqi Chu from 2:30 - 3:30 PM.*\n\n\n\n\n\n\nDate\nSpeaker\nTitle\n\n\n\n\n10/1/24\nZeynep Ertem (Binghampton)\nTBA\n\n\n10/8/24\nCurtis Grant (Northwestern)\nTBA\n\n\n10/8/24\nWeiqi Chu (UMass Amherst)\nTBA\n\n\n10/15/24\nCris Moore (Binghampton)\nTBA\n\n\n10/22/24\nTBA (TBA)\nTBA\n\n\n10/29/24\nTBA (TBA)\nTBA\n\n\n11/5/24\nKeenan Eikenberry (Dartmouth)\nTBA\n\n\n11/12/24\nTBA (TBA)\nTBA\n\n\n11/19/24\nHwai-Ray Tung (University of Utah)\nTBA\n\n\n\n\n\nThis seminar is organized by Linh Huynh (linh.n.huynh@dartmouth.edu), Jonathan Lindbloom (jonathan.t.lindbloom.gr@dartmouth.edu), Rebecca Hardenbrook (rebecca.l.hardenbrook@dartmouth.edu), and Keenan Eikenberry (keenan.j.eikenberry@dartmouth.edu)."
  }
]